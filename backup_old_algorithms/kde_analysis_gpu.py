"""
GPUåŠ é€Ÿçš„æ ¸å¯†åº¦ä¼°è®¡åˆ†ææ¨¡å—
ä½¿ç”¨CuPyå®ç°CUDAåŠ é€Ÿï¼Œæ”¯æŒå¤šGPUå¹¶è¡Œ
ç”¨äºè¯†åˆ«ä¸»è¦ä¸è¿ç»­é¢ç»„
"""

import numpy as np
import logging
try:
    import cupy as cp
    GPU_AVAILABLE = True
except ImportError as e:
    GPU_AVAILABLE = False
    cp = np
    logging.warning(f"CuPyå¯¼å…¥å¤±è´¥: {e}")

logger = logging.getLogger(__name__)


class KDEAnalyzerGPU:
    """
    GPUåŠ é€Ÿçš„åŸºäºæ ¸å¯†åº¦ä¼°è®¡çš„æç‚¹åˆ†æå™¨
    åœ¨ç«‹ä½“æŠ•å½±ä¸Šè¿›è¡Œå¯†åº¦åˆ†æï¼Œè¯†åˆ«ä¸»è¦ä¸è¿ç»­é¢ç»„
    """

    def __init__(self, device_ids=None, use_multi_gpu=False):
        """
        åˆå§‹åŒ–GPUåŠ é€Ÿçš„KDEåˆ†æå™¨

        å‚æ•°:
            device_ids: ä½¿ç”¨çš„GPUè®¾å¤‡IDåˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨æ‰€æœ‰å¯ç”¨GPU
            use_multi_gpu: æ˜¯å¦å¯ç”¨å¤šGPUå¹¶è¡Œ
        """
        self.density = None
        self.main_poles = None
        self.kde_model = None

        if not GPU_AVAILABLE:
            logger.warning("CuPyæœªå®‰è£…ï¼Œå°†å›é€€åˆ°CPUæ¨¡å¼")
            self.use_gpu = False
            return

        self.use_gpu = True
        self.use_multi_gpu = use_multi_gpu

        # è®¾ç½®GPUè®¾å¤‡
        if device_ids is None:
            self.device_ids = list(range(cp.cuda.runtime.getDeviceCount()))
        else:
            self.device_ids = device_ids

        # è·å–GPUå†…å­˜ä¿¡æ¯
        gpu_info = []
        for gpu_id in self.device_ids:
            with cp.cuda.Device(gpu_id):
                mem_info = cp.cuda.Device().mem_info
                total_mem = mem_info[1] / (1024**3)  # GB
                gpu_info.append(f"GPU {gpu_id}: {total_mem:.1f}GB")

        logger.info(f"ğŸš€ GPUåŠ é€Ÿå·²å¯ç”¨ - {'å¤šGPUå¹¶è¡Œ' if use_multi_gpu else 'å•GPU'}")
        logger.info(f"   è®¾å¤‡: {', '.join(gpu_info)}")

    def analyze(self, poles, bin_size=256, min_angle=20, max_sets=10,
                subsample_size=None, primary_gpu=0):
        """
        GPUåŠ é€Ÿåˆ†ææç‚¹åˆ†å¸ƒï¼Œè¯†åˆ«ä¸»è¦ä¸è¿ç»­é¢ç»„

        å‚æ•°:
            poles: æç‚¹åæ ‡æ•°ç»„ (N, 2) - ç«‹ä½“æŠ•å½±åæ ‡
            bin_size: å¯†åº¦ç½‘æ ¼å¤§å°
            min_angle: ä¸»è¦ç»„ä¹‹é—´æœ€å°è§’åº¦ï¼ˆåº¦ï¼‰
            max_sets: æœ€å¤§ä¸è¿ç»­é¢ç»„æ•°
            subsample_size: å­é‡‡æ ·å¤§å°ï¼ŒNoneè¡¨ç¤ºä½¿ç”¨å…¨éƒ¨æ•°æ®
            primary_gpu: ä¸»GPUè®¾å¤‡ID

        è¿”å›:
            density: å¯†åº¦çŸ©é˜µ (CPUæ•°ç»„)
            main_poles: ä¸»è¦æç‚¹åˆ—è¡¨
        """
        logger.info("å¼€å§‹GPUåŠ é€Ÿæ ¸å¯†åº¦ä¼°è®¡åˆ†æ...")

        if not self.use_gpu:
            logger.warning("GPUä¸å¯ç”¨ï¼Œè¯·ä½¿ç”¨CPUç‰ˆæœ¬çš„KDEAnalyzer")
            return None, []

        # è®¾ç½®ä¸»GPU
        with cp.cuda.Device(primary_gpu):
            # åˆ›å»ºç½‘æ ¼ï¼ˆGPUï¼‰
            x_grid = cp.linspace(-1, 1, bin_size)
            y_grid = cp.linspace(-1, 1, bin_size)
            xx, yy = cp.meshgrid(x_grid, y_grid)
            grid_points = cp.vstack([xx.ravel(), yy.ravel()])

            # è½¬ç§»æ•°æ®åˆ°GPU
            poles_gpu = cp.asarray(poles, dtype=cp.float32)

            # å‘é‡åŒ–è¿‡æ»¤æœ‰æ•ˆæç‚¹ï¼ˆåœ¨å•ä½åœ†å†…ï¼‰
            valid_mask = cp.sum(poles_gpu**2, axis=1) <= 1
            valid_poles = poles_gpu[valid_mask]

            if len(valid_poles) < 10:
                logger.warning("æœ‰æ•ˆæç‚¹æ•°é‡å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œå¯†åº¦åˆ†æ")
                return None, []

            logger.info(f"æœ‰æ•ˆæç‚¹æ•°é‡: {len(valid_poles)}")

            # å­é‡‡æ ·ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if subsample_size is not None and len(valid_poles) > subsample_size:
                logger.info(f"å­é‡‡æ ·è‡³ {subsample_size} ä¸ªç‚¹")
                indices = cp.random.choice(len(valid_poles), subsample_size, replace=False)
                valid_poles = valid_poles[indices]
            else:
                logger.info(f"ä½¿ç”¨å…¨éƒ¨ {len(valid_poles)} ä¸ªæç‚¹")

            # GPUåŠ é€ŸKDEè®¡ç®—
            logger.info("GPUåŠ é€ŸKDEè®¡ç®—...")
            density_flat = self._compute_kde_gpu(valid_poles, grid_points)

            # è½¬æ¢ä¸º2Då¯†åº¦çŸ©é˜µ
            self.density = cp.asnumpy(density_flat.reshape(xx.shape))
            xx_cpu = cp.asnumpy(xx)
            yy_cpu = cp.asnumpy(yy)

        # å¯»æ‰¾å¯†åº¦å³°å€¼ï¼ˆåœ¨CPUä¸Šï¼‰
        self.main_poles = self._find_density_peaks(
            xx_cpu, yy_cpu, self.density,
            min_angle=min_angle,
            max_sets=max_sets
        )

        logger.info(f"è¯†åˆ«åˆ° {len(self.main_poles)} ä¸ªä¸»è¦ä¸è¿ç»­é¢ç»„")

        return self.density, self.main_poles

    def _compute_kde_gpu(self, poles, grid_points):
        """
        å¤šGPUåŠ é€Ÿçš„KDEè®¡ç®—ï¼ˆçœŸæ­£çš„å¤šGPUæ•°æ®å¹¶è¡Œï¼‰

        å‚æ•°:
            poles: æœ‰æ•ˆæç‚¹ (GPUæ•°ç»„)
            grid_points: ç½‘æ ¼ç‚¹ (GPUæ•°ç»„)

        è¿”å›:
            density: å¯†åº¦å€¼ (GPUæ•°ç»„)
        """
        n_poles = poles.shape[0]
        n_grid = grid_points.shape[1]

        # è®¡ç®—å¸¦å®½ (Scott's rule)
        d = poles.shape[1]  # ç»´åº¦
        bw_factor = n_poles ** (-1.0 / (d + 4))
        cov = cp.cov(poles.T)
        bandwidth = bw_factor * cp.sqrt(cp.diag(cov))

        logger.info(f"KDEå¸¦å®½: {cp.asnumpy(bandwidth)}")

        # å¦‚æœå¯ç”¨å¤šGPUå¹¶è¡Œ
        if self.use_multi_gpu and len(self.device_ids) > 1:
            return self._compute_kde_multi_gpu(poles, grid_points, bandwidth)
        else:
            return self._compute_kde_single_gpu(poles, grid_points, bandwidth)

    def _compute_kde_multi_gpu(self, poles, grid_points, bandwidth):
        """
        çœŸæ­£çš„å¤šGPUå¹¶è¡ŒKDEè®¡ç®— - ä½¿ç”¨çº¿ç¨‹æ± å®ç°å¹¶è¡Œ

        å°†è¯„ä¼°ç‚¹åˆ†é…åˆ°å¤šä¸ªGPUä¸Šå¹¶è¡Œè®¡ç®—
        """
        import threading

        n_poles = poles.shape[0]
        n_grid = grid_points.shape[1]
        n_gpus = len(self.device_ids)

        logger.info(f"ğŸš€ å¯åŠ¨å¤šGPUå¹¶è¡Œè®¡ç®—: {n_gpus} ä¸ªGPU")

        # å°†ç½‘æ ¼ç‚¹å‡åŒ€åˆ†é…åˆ°å„ä¸ªGPU
        grid_per_gpu = (n_grid + n_gpus - 1) // n_gpus

        # åœ¨ä¸»GPUä¸Šå‡†å¤‡æ•°æ®ï¼ˆè½¬ä¸ºCPUé¿å…è·¨GPUå¤åˆ¶é—®é¢˜ï¼‰
        poles_cpu = cp.asnumpy(poles)
        grid_cpu = cp.asnumpy(grid_points)
        bandwidth_cpu = cp.asnumpy(bandwidth)

        # å­˜å‚¨æ¯ä¸ªGPUçš„ç»“æœ
        gpu_results = {}

        def compute_on_gpu(gpu_id, start_idx, end_idx):
            """åœ¨æŒ‡å®šGPUä¸Šè®¡ç®—å¯†åº¦"""
            with cp.cuda.Device(gpu_id):
                # å°†æ•°æ®å¤åˆ¶åˆ°è¯¥GPU
                poles_gpu = cp.array(poles_cpu, dtype=cp.float32)
                grid_gpu = cp.array(grid_cpu[:, start_idx:end_idx], dtype=cp.float32)
                bandwidth_gpu = cp.array(bandwidth_cpu, dtype=cp.float32)

                logger.info(f"GPU {gpu_id}: å¼€å§‹å¤„ç†ç½‘æ ¼ç‚¹ {start_idx}-{end_idx} (å…±{end_idx-start_idx}ä¸ª)")

                # åœ¨è¯¥GPUä¸Šè®¡ç®—å¯†åº¦
                density_gpu = self._kde_kernel_gpu(poles_gpu, grid_gpu, bandwidth_gpu)

                # å°†ç»“æœè½¬ä¸ºCPUæ•°ç»„ï¼ˆé¿å…è·¨GPUä¼ è¾“ï¼‰
                density_cpu = cp.asnumpy(density_gpu)

                # å­˜å‚¨ç»“æœ
                gpu_results[gpu_id] = (start_idx, end_idx, density_cpu)

                logger.info(f"GPU {gpu_id}: è®¡ç®—å®Œæˆ")

                # æ¸…ç†GPUå†…å­˜
                del poles_gpu, grid_gpu, bandwidth_gpu, density_gpu
                cp.get_default_memory_pool().free_all_blocks()

        # åˆ›å»ºçº¿ç¨‹æ± ï¼Œæ¯ä¸ªGPUä¸€ä¸ªçº¿ç¨‹
        threads = []
        for gpu_idx, gpu_id in enumerate(self.device_ids):
            # è®¡ç®—è¯¥GPUè´Ÿè´£çš„ç½‘æ ¼ç‚¹èŒƒå›´
            start_idx = gpu_idx * grid_per_gpu
            end_idx = min((gpu_idx + 1) * grid_per_gpu, n_grid)

            if start_idx >= n_grid:
                break

            # å¯åŠ¨çº¿ç¨‹
            thread = threading.Thread(
                target=compute_on_gpu,
                args=(gpu_id, start_idx, end_idx)
            )
            thread.start()
            threads.append(thread)

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        # åœ¨ä¸»GPUä¸Šåˆå¹¶æ‰€æœ‰ç»“æœ
        with cp.cuda.Device(self.device_ids[0]):
            density = cp.zeros(n_grid, dtype=cp.float32)
            for gpu_id in sorted(gpu_results.keys()):
                start_idx, end_idx, density_cpu = gpu_results[gpu_id]
                density[start_idx:end_idx] = cp.array(density_cpu)
                logger.info(f"GPU {gpu_id}: ç»“æœå·²åˆå¹¶")

        logger.info(f"âœ… å¤šGPUå¹¶è¡Œè®¡ç®—å®Œæˆ")
        return density

    def _compute_kde_single_gpu(self, poles, grid_points, bandwidth):
        """
        å•GPUçš„KDEè®¡ç®—ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        """
        n_grid = grid_points.shape[1]

        # åˆ†æ‰¹è®¡ç®—ä»¥èŠ‚çœæ˜¾å­˜
        batch_size = min(50000, n_grid)
        n_batches = (n_grid + batch_size - 1) // batch_size

        density = cp.zeros(n_grid, dtype=cp.float32)

        for i in range(n_batches):
            start_idx = i * batch_size
            end_idx = min((i + 1) * batch_size, n_grid)
            batch_grid = grid_points[:, start_idx:end_idx]

            # è®¡ç®—æ¯ä¸ªç½‘æ ¼ç‚¹çš„å¯†åº¦
            batch_density = self._kde_kernel_gpu(poles, batch_grid, bandwidth)
            density[start_idx:end_idx] = batch_density

            if (i + 1) % max(1, n_batches // 10) == 0:
                logger.info(f"KDEè¿›åº¦: {100 * (i + 1) // n_batches}%")

        return density

    def _kde_kernel_gpu(self, data, eval_points, bandwidth):
        """
        GPUåŠ é€Ÿçš„KDEæ ¸å‡½æ•°è®¡ç®—ï¼ˆé«˜æ–¯æ ¸ï¼‰- å†…å­˜ä¼˜åŒ–ç‰ˆ

        å‚æ•°:
            data: æ•°æ®ç‚¹ (n_data, d) GPUæ•°ç»„
            eval_points: è¯„ä¼°ç‚¹ (d, n_eval) GPUæ•°ç»„
            bandwidth: å¸¦å®½ (d,) GPUæ•°ç»„

        è¿”å›:
            density: å¯†åº¦å€¼ (n_eval,) GPUæ•°ç»„
        """
        n_data = data.shape[0]
        n_eval = eval_points.shape[1]
        d = data.shape[1]

        # æ ¹æ®å¯ç”¨æ˜¾å­˜åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
        mem_info = cp.cuda.Device().mem_info
        available_mem = mem_info[0]  # å¯ç”¨æ˜¾å­˜ï¼ˆå­—èŠ‚ï¼‰

        # æ›´ä¿å®ˆçš„å†…å­˜ä¼°ç®—
        # é¢„ä¼°å†…å­˜éœ€æ±‚ï¼šdata_batch * eval_batch * 4 bytes (float32) * 5 (ä¸­é—´æ•°ç»„+å®‰å…¨ä½™é‡)
        # åªä½¿ç”¨30%çš„å¯ç”¨æ˜¾å­˜
        safe_mem = available_mem * 0.3

        # é¦–å…ˆç¡®å®šè¯„ä¼°æ‰¹æ¬¡å¤§å°ï¼ˆè¾ƒå°ï¼‰
        eval_batch_size = 100  # å›ºå®šè¾ƒå°çš„è¯„ä¼°æ‰¹æ¬¡

        # ç„¶åè®¡ç®—æ•°æ®æ‰¹æ¬¡å¤§å°
        max_data_batch = int(safe_mem / (eval_batch_size * 4 * 5))
        data_batch_size = max(500, min(max_data_batch, 50000))  # é™åˆ¶åœ¨500-50000ä¹‹é—´

        logger.info(f"GPU KDEå†…å­˜ä¼˜åŒ–: å¯ç”¨æ˜¾å­˜={available_mem/(1024**3):.2f}GB, "
                   f"æ•°æ®æ‰¹æ¬¡={data_batch_size}, è¯„ä¼°æ‰¹æ¬¡={eval_batch_size}, "
                   f"é¢„ä¼°æ¯æ‰¹å†…å­˜={(data_batch_size * eval_batch_size * 4 * 5)/(1024**3):.2f}GB")

        density = cp.zeros(n_eval, dtype=cp.float32)
        normalization = (2 * cp.pi) ** (-d / 2) * cp.prod(bandwidth) ** (-1)

        total_eval_batches = (n_eval + eval_batch_size - 1) // eval_batch_size
        logger.info(f"KDEè®¡ç®—: {n_data} æ•°æ®ç‚¹ Ã— {n_eval} è¯„ä¼°ç‚¹, "
                   f"å…± {total_eval_batches} ä¸ªè¯„ä¼°æ‰¹æ¬¡")

        # åŒå±‚åˆ†æ‰¹ï¼šå…ˆåˆ†æ‰¹è¯„ä¼°ç‚¹ï¼Œå†åˆ†æ‰¹æ•°æ®ç‚¹
        for eval_batch_idx, i in enumerate(range(0, n_eval, eval_batch_size)):
            end_idx = min(i + eval_batch_size, n_eval)
            batch_eval = eval_points[:, i:end_idx]  # (d, current_eval_batch)
            batch_density = cp.zeros(end_idx - i, dtype=cp.float32)

            # å¯¹æ•°æ®ç‚¹åˆ†æ‰¹å¤„ç†å¹¶ç´¯åŠ ï¼ˆä¿æŒç²¾åº¦ï¼‰
            total_data_batches = (n_data + data_batch_size - 1) // data_batch_size
            for data_batch_idx, j in enumerate(range(0, n_data, data_batch_size)):
                data_end = min(j + data_batch_size, n_data)
                batch_data = data[j:data_end, :]  # (current_data_batch, d)

                # å¹¿æ’­è®¡ç®—è·ç¦»
                # batch_data: (current_data_batch, d) -> (current_data_batch, d, 1)
                # batch_eval: (d, current_eval_batch) -> (1, d, current_eval_batch)
                data_expanded = batch_data[:, :, cp.newaxis]
                eval_expanded = batch_eval[cp.newaxis, :, :]

                # è®¡ç®—æ ‡å‡†åŒ–è·ç¦»
                diff = (data_expanded - eval_expanded) / bandwidth[cp.newaxis, :, cp.newaxis]

                # é«˜æ–¯æ ¸
                exponent = -0.5 * cp.sum(diff ** 2, axis=1)  # (current_data_batch, current_eval_batch)
                kernels = cp.exp(exponent)

                # ç´¯åŠ è¿™æ‰¹æ•°æ®ç‚¹çš„è´¡çŒ®ï¼ˆä¿æŒç²¾åº¦ï¼‰
                batch_density += cp.sum(kernels, axis=0)

                # æ¸…ç†æ˜¾å­˜
                del data_expanded, eval_expanded, diff, exponent, kernels
                cp.get_default_memory_pool().free_all_blocks()

                # è¿›åº¦æŠ¥å‘Š
                if (data_batch_idx + 1) % max(1, total_data_batches // 5) == 0:
                    progress = (eval_batch_idx * total_data_batches + data_batch_idx + 1) / (total_eval_batches * total_data_batches) * 100
                    logger.info(f"KDEè¿›åº¦: {progress:.1f}% (è¯„ä¼°æ‰¹æ¬¡ {eval_batch_idx+1}/{total_eval_batches}, "
                              f"æ•°æ®æ‰¹æ¬¡ {data_batch_idx+1}/{total_data_batches})")

            # å½’ä¸€åŒ–ï¼šé™¤ä»¥æ€»æ•°æ®ç‚¹æ•°
            density[i:end_idx] = normalization * batch_density / n_data

            # æ¸…ç†æ˜¾å­˜
            del batch_eval, batch_density
            cp.get_default_memory_pool().free_all_blocks()

        return density

    def _find_density_peaks(self, xx, yy, density, min_angle=20, max_sets=10):
        """
        å¯»æ‰¾å¯†åº¦å³°å€¼ç‚¹ï¼ˆCPUç‰ˆæœ¬ï¼‰

        å‚æ•°:
            xx, yy: ç½‘æ ¼åæ ‡ (CPUæ•°ç»„)
            density: å¯†åº¦çŸ©é˜µ (CPUæ•°ç»„)
            min_angle: å³°å€¼ä¹‹é—´æœ€å°è§’åº¦ï¼ˆåº¦ï¼‰
            max_sets: æœ€å¤§å³°å€¼æ•°

        è¿”å›:
            peaks: å³°å€¼ç‚¹åˆ—è¡¨
        """
        # å¯»æ‰¾å±€éƒ¨æœ€å¤§å€¼
        flat_density = density.flatten()
        sorted_indices = np.argsort(flat_density)[::-1]

        peaks = []
        min_angle_rad = np.radians(min_angle)

        for idx in sorted_indices:
            if len(peaks) >= max_sets:
                break

            # è·å–å³°å€¼åæ ‡
            i, j = np.unravel_index(idx, density.shape)
            x, y = xx[i, j], yy[i, j]

            # æ£€æŸ¥æ˜¯å¦åœ¨å•ä½åœ†å†…
            if x ** 2 + y ** 2 > 1:
                continue

            # æ£€æŸ¥ä¸å·²æœ‰å³°å€¼çš„è§’åº¦
            too_close = False
            for px, py, _ in peaks:
                angle = self._calculate_angle_between_poles((x, y), (px, py))
                if angle < min_angle_rad:
                    too_close = True
                    break

            if not too_close:
                peaks.append((x, y, flat_density[idx]))

        # è½¬æ¢ä¸ºäº§çŠ¶
        main_poles = []
        for x, y, density_value in peaks:
            dip_dir, dip = self._stereo_to_orientation(x, y)
            main_poles.append({
                'stereo_x': x,
                'stereo_y': y,
                'dip_direction': dip_dir,
                'dip': dip,
                'density': density_value
            })

        return main_poles

    def _calculate_angle_between_poles(self, pole1, pole2):
        """è®¡ç®—ä¸¤ä¸ªæç‚¹ä¹‹é—´çš„è§’åº¦"""
        v1 = self._stereo_to_vector(pole1[0], pole1[1])
        v2 = self._stereo_to_vector(pole2[0], pole2[1])
        cos_angle = np.clip(np.dot(v1, v2), -1, 1)
        return np.arccos(cos_angle)

    def _stereo_to_vector(self, x, y):
        """ç«‹ä½“æŠ•å½±åæ ‡è½¬æ¢ä¸ºå•ä½å‘é‡"""
        r2 = x ** 2 + y ** 2
        if r2 > 1:
            return np.array([0, 0, 1])

        z = (1 - r2) / (1 + r2)
        scale = 2 / (1 + r2)
        return np.array([x * scale, y * scale, z])

    def _stereo_to_orientation(self, x, y):
        """ç«‹ä½“æŠ•å½±åæ ‡è½¬æ¢ä¸ºäº§çŠ¶"""
        vector = self._stereo_to_vector(x, y)

        # è®¡ç®—å€¾å‘
        dip_direction = np.degrees(np.arctan2(vector[1], vector[0]))
        if dip_direction < 0:
            dip_direction += 360

        # è®¡ç®—å€¾è§’
        dip = np.degrees(np.arccos(np.abs(vector[2])))

        return dip_direction, dip
